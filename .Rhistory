import warnings
import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error as mae
warnings.filterwarnings('ignore')
filtered_df=pd.read_csv("data/filtered_df.csv", sep=";")
filtered_df.set_index('time',inplace=True)
filtered_df.index=pd.to_datetime(filtered_df.index,format="%d/%m/%Y %H:%M")
filtered_df.isna().sum()
filtered_df.dropna(inplace=True)
power=filtered_df.iloc[:,0].dropna()
power = filtered_df.iloc[:,0].dropna()
X = power.to_numpy()
q_80 = int(len(X) * .8)
train = power.iloc[:q_80]
test = power.iloc[q_80:]
# Plot the train and test data with dates on the x-axis
plt.figure(figsize=(14, 7))
plt.plot(train.index, train, color='blue', label='Train')
plt.plot(test.index, test, color='red', label='Test')
plt.legend()
plt.xlabel('Date')
plt.ylabel('Power')
plt.title('Train and Test Data')
plt.show()
plt.close()
# Plot the train and test data with dates on the x-axis
plt.figure(figsize=(14, 7))
plt.plot(train.index, train, color='blue', label='Train')
plt.plot(test.index, test, color='red', label='Test')
plt.legend()
plt.xlabel('Date')
plt.ylabel('Power')
plt.title('Train and Test Data')
plt.show()
plt.close()
print(train.shape)
# power = filtered_df.iloc[:, ].dropna()
X = filtered_df.to_numpy()
X[:10, :10]
# power = filtered_df.iloc[:, ].dropna()
X = filtered_df.to_numpy()
X[:10, :4]
# power = filtered_df.iloc[:, ].dropna()
X = filtered_df.to_numpy()
X[:10, :5]
# power = filtered_df.iloc[:, ].dropna()
X = filtered_df.to_numpy()
X[:10, :4]
q_80 = int(len(X) * .8)
q_80 = int(len(X) * .8)
train = filtered_df.iloc[:q_80, :]
test = filtered_df.iloc[q_80:, :]
print(train.shape)
train[:10,:4]
train.head()
# Plot the train and test data with dates on the x-axis
plt.figure(figsize=(14, 7))
plt.plot(train.index, train, color='blue', label='Train')
plt.plot(test.index, test, color='red', label='Test')
plt.legend()
plt.xlabel('Date')
plt.ylabel('Power')
plt.title('Train and Test Data')
plt.show()
plt.close()
# Plot the train and test data with dates on the x-axis
plt.figure(figsize=(14, 7))
plt.plot(train.index, train["Active_Power"], color='blue', label='Train')
plt.plot(test.index, test["Active_Power"], color='red', label='Test')
plt.legend()
plt.xlabel('Date')
plt.ylabel('Power')
plt.title('Train and Test Data')
plt.show()
plt.close()
# Plot the train and test data with dates on the x-axis
plt.figure(figsize=(14, 7))
plt.plot(train.index, train["Active_Power"], color='blue', label='Train')
plt.plot(test.index, test["Active_Power"], color='red', label='Test')
plt.legend()
plt.xlabel('Date')
plt.ylabel('Power')
plt.title('Active_Power. Train and Test Data')
plt.show()
plt.close()
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error
filtered_df.columns
filtered_df.columns[:-1]
filtered_df.columns[1:]
target = filtered_df.columns[0:]
features = filtered_df.columns[1:]
print(target, features)
target = filtered_df.columns[0:]
features = filtered_df.columns[1:]
print(target)
filtered_df.columns
target = filtered_df.columns.to_list()[0:]
print(target)
target = (filtered_df.columns.to_list())[0]
print(target)
target = filtered_df.columns[0]
print(target)
features = filtered_df.columns[1:]
print(features)
target = filtered_df.columns[0]
features = filtered_df.columns[1:]
print(target)
print(features)
target = filtered_df.columns[0]
features = filtered_df.columns[1:]
print("target = ", target)
print("features = ", features)
target = filtered_df.columns[0]
features = filtered_df.columns[1:]
print("target = ", target)
print("features = ", features.to_list())
ts_cv.split(train):
ts_cv = TimeSeriesSplit(n_splits=10)
ts_cv
fold = 0
preds = []
scores = []
ts_cv = TimeSeriesSplit(n_splits=10)
fold = 0
preds = []
scores = []
for train_idx, val_idx in ts_cv.split(train):
train_fld = filtered_df.iloc[train_idx]
val_fld = filtered_df.iloc[val_idx]
# #agregar atributos al set de entrenamiento y prueba
# train_fld = create_attributes(train)
# test = create_attributes(test)
# features = ['day','dayofweek','month','quarter','year','dayofyear']
# target = ['kWh']
X_train = train_fld[features]
y_train = train_fld[target]
X_val = val_fld[features]
y_val = val_fld[target]
#crear instancia del regresor
xgb_reg = xgb.XGBRegressor(booster='gbtree',
seed=42,
n_estimators=1000,
early_stopping_rounds=50,
objective='reg:squarederror',
reg_lambda=0.001,
max_depth=5,
eta=0.01)
#entrenar modelo
xgb_reg.fit(X_train, y_train,
eval_set=[(X_train, y_train), (X_val, y_val)],
verbose=100)
#predicciones y evaluacion
y_pred = xgb_reg.predict(X_val)
preds.append(y_pred)
score = np.sqrt(mean_squared_error(y_val, y_pred))
scores.append(score)
ts_cv = TimeSeriesSplit(n_splits=10)
fold = 0
preds = []
scores = []
for train_idx, val_idx in ts_cv.split(train):
train_fld = filtered_df.iloc[train_idx]
val_fld = filtered_df.iloc[val_idx]
# #agregar atributos al set de entrenamiento y prueba
# train_fld = create_attributes(train)
# test = create_attributes(test)
# features = ['day','dayofweek','month','quarter','year','dayofyear']
# target = ['kWh']
X_train = train_fld[features]
y_train = train_fld[target]
X_val = val_fld[features]
y_val = val_fld[target]
#crear instancia del regresor
xgb_reg = xgb.XGBRegressor(booster='gbtree',
n_jobs = -1,
seed=42,
n_estimators=1000,
early_stopping_rounds=50,
objective='reg:squarederror',
reg_lambda=0.001,
max_depth=5,
eta=0.01)
#entrenar modelo
xgb_reg.fit(X_train, y_train,
eval_set=[(X_train, y_train), (X_val, y_val)],
verbose=100)
#predicciones y evaluacion
y_pred = xgb_reg.predict(X_val)
preds.append(y_pred)
score = np.sqrt(mean_squared_error(y_val, y_pred))
scores.append(score)
print('Fold scores:', scores)
print('Avg. Score:', np.mean(scores))
ts_cv = TimeSeriesSplit(n_splits=10)
ts_cv_train = ts_cv.split(train):
ts_cv = TimeSeriesSplit(n_splits=10)
ts_cv_train = ts_cv.split(train)
ts_cv_train
fig, axs = plt.subplots(4, 1, figsize=(15, 15), sharex=True)
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = pw_clean.iloc[train_idx]
test_fld = pw_clean.iloc[val_idx]
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
fig, axs = plt.subplots(4, 1, figsize=(15, 15), sharex=True)
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
# axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
train_idx, val_idx = next(ts_cv.split(train))
train_idx,
val_idx
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
fold = 0
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
train_fld['Active_Power'].
train_fld['Active_Power']
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
type(train_fld)
type(train_fld['Active_Power'])
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
axs = axs.flatten()
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_idx, val_idx = next(ts_cv.split(train))
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
type(train_fld['Active_Power'])
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
# axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
axs = axs.flatten()
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
type(train_fld['Active_Power'])
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
# axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
axs = axs.flatten()
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
type(train_fld['Active_Power'])
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
# axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
test_fld
test_fld.index
preds_df = pd.DataFrame(index=pred_dates)
pred_dates = test_fld.index
preds_df = pd.DataFrame(index=pred_dates)
preds_df
test
test.shape
np.zeros(test.shape[0])
test['pred'] = np.zeros(test.shape[0])
test
train['Future'] = False
test['Future'] = True
pred_df = pd.concat([train, test])
pred_df
#crear instancia del regresor
xgb_regf = xgb.XGBRegressor(booster='gbtree',
seed=42,
n_estimators=1000,
early_stopping_rounds=50,
objective='reg:squarederror',
reg_lambda=0.001,
max_depth=5,
eta=0.01)
X_train = train[features]
y_train = train[target]
xgb_regf.fit(X_train, y_train,
eval_set=[(X_train, y_train)],
verbose=100)
test['pred'] = xgb_regf.predict(future_pred_pw[features])
test['pred'] = xgb_regf.predict(test[features])
test['pred']
#graficar
ax = train['Active_Power']\
.plot(figsize=(20, 6), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, axs = plt.subplots(5, 2, figsize=(15, 15), sharex=True)
axs = axs.flatten()
fold = 0
for train_idx, val_idx in ts_cv.split(train):
train_fld = train.iloc[train_idx]
test_fld = train.iloc[val_idx]
type(train_fld['Active_Power'])
train_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Training Set',
title=f'Train/Test Split Fold {fold}')
test_fld['Active_Power'].plot(ax=axs[fold], lw=1,
label='Test Set')
# axs[fold].axvline(test_fld.index.min(), color='black', ls='--')
fold += 1
plt.show()
plt.close()
#graficar
ax = train['Active_Power']\
.plot(figsize=(20, 6), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power']\
.plot(figsize=(20, 6), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power']\
.plot(figsize=(20, 6), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power']\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[:-1000, :]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000:, :]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
train['Active_Power'].
train['Active_Power']
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'] .iloc[5000:, :]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000:, :]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
train['Active_Power'].iloc[5000:, :]
train['Active_Power'].iloc[5000:]
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
train['Active_Power'].iloc[5000:]
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power']\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000:]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
# test['pred'].plot(style='-', lw=1.5)
# test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5000:]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
from sklearn.metrics import mean_absolute_percentage_error as mape
mape(test['Active_Power'], test['Pred'])
mape(test['Active_Power'], test['pred'])
test['pred']
test['Active_Power'],
mape(test['Active_Power'], test['pred'] )
test['Active_Power'] + 1,
mape(test['Active_Power'] + 1, test['pred'] + 1 )
test['Active_Power'] - test['pred']
np.max(test['Active_Power'] - test['pred'])
fig, ax = plt.subplots()
#graficar
ax = train['Active_Power'].iloc[5600:]\
.plot(figsize=(30, 12), lw=1.5, title='XGBoost')
test['pred'].plot(style='-', lw=1.5)
test['Active_Power'].plot(style='-', lw=1.5)
# plt.legend(['Historic Data','Predictions'], fontsize=14)
plt.show()
mae(test['Active_Power'], test['pred'])
np.mean(np.abs(test['Active_Power'] - test['pred']))
library(tidyverse)
data <- read_csv("./spain_energy_market.csv")
View(data)
data2 <- data %>%
pivot_wider(names_from = "name", values_from = "value")
View(data2)
setwd("~/code/fsansegundo.github.io")
